<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>AI Assessor</title>

    <!-- Bootstrap -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/css/bootstrap.min.css" integrity="sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu" crossorigin="anonymous">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
      <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
    <nav class="navbar navbar-default">
        <div class="container-fluid">
          <!-- Brand and toggle get grouped for better mobile display -->
          <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="#">AI Assessor</a>
          </div>
      
          <!-- Collect the nav links, forms, and other content for toggling -->
          <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav">
              <li class="active"><a href="#main-body">About <span class="sr-only">(current)</span></a></li>
              <li><a href="#">People</a></li>
            </ul>
          </div><!-- /.navbar-collapse -->
        </div><!-- /.container-fluid -->
      </nav>

      <div id="main-body">
        <div class="panel panel-primary">
            <div class="panel-heading">Using Computer Vision Techniques to Identify Medical Students' Safety
                Behaviors in Objective Structured Clinical Examinations</div>
            <div class="panel-body">
                This proposal aims to harness computer vision to detect key safety practices, like hand hygiene and glove use, during Objective Structured Clinical Examinations (OSCEs) through video analysis. Proposed research tasks include: constructing an object detection database with tagged images of items such as gloves and sanitizers; training a model to recognize safety behaviors; and assessing the model’s reliability and fairness. Utilizing 66,048 recorded SP encounters since 2016, which encompass 132,096 videos with comprehensive workflow replication, and associated demographic data, we plan to evaluate the consistency of our model against standard SP checklists and scrutinize the assessment tool’s validity. Employing Python for all tasks, the project also aims to investigate the objectivity of the model’s results across various subgroups using background variables. The expected outcome is an advancement in the accuracy and efficacy of simulation-based assessments within UME, which could contribute positively to future assessment practices.
            </div>
        </div>

        <div class="panel panel-primary">
            <div class="panel-heading">Developing Speech-to-Text Models for Medical Undergraduates’ Clinical Competency in Objective Structured Clinical Examinations Using Natural Language Processing</div>
            <div class="panel-body">
                The proposed study will apply natural language processing techniques to build a speech-to-text model that can transcribe conversations to text. After the model is built, we will conduct extract and identify students’ behaviors and movements from video footage and use such data to assess aspects of their clinical performance in the OSCE’s physical examination sections. 
<br><br>Aim 1: Build video speech-to-text models using natural language processing. We will design an annotation scheme based on the important entities and activities occurring in encounters. We will transcribe the videos, annotate the text of the conversations with the related entities and activities, align them with the checklist scores, and build speech-to-text models using natural language processing. 
<br><br>Aim 2: Conduct group difference analysis to examine the speech-to-text model performance. Videos and the transcribed texts from the speech-to-text model in Aim 1 will be linked with medical students’ and SPs’ demographic variables. Group difference analyses will be conducted to evaluate the fairness of the speech-to-text model.

            </div>
        </div>
       
        <!-- <div class="panel panel-info">...</div>
        <div class="panel panel-warning">...</div>
        <div class="panel panel-danger">...</div> -->
      </div>

    <div id="people">
        <div class="panel panel-success">
            <div class="panel-heading">People</div>
            <div class="panel-body">
                Chi Chang, PhD., MS, (Principal Investigator): Assistant Professor of Medical Education Research and Development and Department of Epidemiology and Biostatistics, College of Human Medicine, Michigan State University
            <br><br>
            Heather S. Laird-Fick, MD., MPH., (Co-Principal Investigator): Director of Assessment, Professor of Medicine, College of Human Medicine, Michigan State University
            <br><br>
            Robert Malinowski, PhD., DVM., MA., (Co-Investigator): Associate Director of Assessment, Assistant Professor of Medical Education Research and Development and College of Human Medicine, Michigan State University
            <br><br>
            Yu Kong, PhD., (Co-Investigator): Assistant Professor, Department of Computer Science and Engineering, College of Engineering, Michigan State University
            <br><br>
            Yoon Soo Park, PhD., (Consultant): Director of Health Professions Education Research, Massachusetts General Hospital; Associate Professor, Harvard Medical School.
            </div>
        </div>
    </div>

    <div id="presentations">
        <div class="panel panel-info">
            <div class="panel-heading">Presentations</div>
            <div class="panel-body">
                Chang, C., Hong Zhuang, Yu Kong, & Laird-Fick, H. (2023). Using Computer Vision to Assess 
Students’ Safety Behaviors in an Objective Structured Clinical Examination. Poster presented at the 
annual ChangeMedEd conference, Chicago (Sep. 2023). 
            </div>
        </div>
    </div>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://code.jquery.com/jquery-1.12.4.min.js" integrity="sha384-nvAa0+6Qg9clwYCGGPpDQLVpLNn0fRaROjHqs13t4Ggj3Ez50XnGQqc/r8MhnRDZ" crossorigin="anonymous"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/js/bootstrap.min.js" integrity="sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd" crossorigin="anonymous"></script>
  </body>
</html>